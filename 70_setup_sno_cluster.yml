---
- name: Play for preparing to OCP4 single-node setup
  hosts: vm_host
  become: true
  vars_files:
    - vars/sno_vars.yml
    - vars/infra_vars.yml
  tasks:
    - name: Preparing workspace
      ansible.builtin.file:
        state: directory
        path: "{{ workspace_directory.base_path }}/{{ cluster.name }}/{{ workspace_directory.config_dir }}"
        mode: "0755"

    - name: Creating ssh keys if the do not exist
      community.crypto.openssh_keypair:
        path: "~/.ssh/id_rsa_{{ cluster.name }}"

    - name: Retrieve image for current version
      ansible.builtin.shell: "curl -s {{ downloads.ocp.base_url }}/{{ cluster.version }}/release.txt | grep 'Pull From: quay.io' | awk -F ' ' '{print $3}'"
      register: image_version

    - name: Save version as fact
      ansible.builtin.set_fact:
        release_image: "{{ image_version.stdout }}"

    - name: Downloading Openshift CLI
      ansible.builtin.unarchive:
        src: "{{ downloads.ocp.base_url }}/{{ cluster.version }}/openshift-client-linux-{{ cluster.version }}.tar.gz"
        dest: /usr/bin
        remote_src: true
      when:
        - cluster.version != "latest"
        - cluster.version != "fast"
        - cluster.version != "stable"
        - cluster.version != "candidate"

    - name: Downloading Openshift CLI
      ansible.builtin.unarchive:
        src: "{{ downloads.ocp.base_url }}/{{ cluster.version }}/openshift-client-linux.tar.gz"
        dest: /usr/bin
        remote_src: true
      when: cluster.version == "latest" or cluster.version == "fast" or cluster.version == "stable" or cluster.version == "candidate"

    - name: Checking for OCP cli tool
      ansible.builtin.shell: oc
      register: output
      failed_when: output.rc !=0

    - name: Download coreOS ISO and save it locally
      ansible.builtin.get_url:
        url: "{{ downloads.coreos.live_media }}"
        dest: "{{ workspace_directory.base_path }}/{{ cluster.name }}/coreos.iso"
        mode: 0755

    - name: Download coreOS-installer and save it locally
      ansible.builtin.get_url:
        url: "{{ downloads.coreos.installer }}"
        dest: /usr/bin/coreos-installer
        mode: +x

    - name: Ensure NM configuration directory exists
      ansible.builtin.file:
        path: /etc/NetworkManager/conf.d
        state: directory
        mode: "0755"

    - name: Ensure NM dnsmasq directory exists
      ansible.builtin.file:
        path: /etc/NetworkManager/dnsmasq.d
        state: directory
        mode: "0755"

    - name: Configure NetworkManager for local DNS
      ansible.builtin.copy:
        src: files/localdns.conf
        dest: /etc/NetworkManager/conf.d/{{ cluster.name }}-localdns.conf
        mode: "0755"

    - name: Configure NetworkManager for libvirt network
      ansible.builtin.template:
        src: templates/libvirt_dnsmasq_sno.j2
        dest: "/etc/NetworkManager/dnsmasq.d/{{ cluster.name }}-libvirt_dnsmasq.conf"
        mode: "0755"

    - name: Take care of systemd-resolved on F33 and Ubuntu hosts
      block:
        - name: Ensure systemd-resolved config dir is present
          ansible.builtin.file:
            path: /etc/systemd/resolved.conf.d/
            state: directory
            mode: "0755"

        - name: Enable localdns if systemd-resolved is present
          ansible.builtin.template:
            src: systemd-resolved.j2
            dest: /etc/systemd/resolved.conf.d/{{ cluster.name }}-local.conf
            mode: "0755"

        - name: Restart systemd-resolved
          ansible.builtin.service:
            name: systemd-resolved
            state: restarted

        - name: Backup resolv.conf for further debug
          ansible.builtin.copy:
            src: /etc/resolv.conf
            dest: /etc/resolv.conf.bak
            remote_src: true
            mode: "0755"

        - name: Ensure systemd-resolved config dir is present
          ansible.builtin.file:
            src: /run/systemd/resolve/resolv.conf
            dest: /etc/resolv.conf
            state: link
            force: true

      when: (ansible_distribution == 'Fedora' and ansible_distribution_major_version | int >= 33)

    - name: Copy pull secret to a file
      ansible.builtin.copy:
        content: "{{ cluster.pullSecret }}"
        dest: "{{ workspace_directory.base_path }}/{{ cluster.name }}/pull-secret"
        mode: "0755"

    - name: Extract openshift-baremetal-install from release image
      ansible.builtin.shell: "oc adm release extract --registry-config {{ workspace_directory.base_path }}/{{ cluster.name }}/pull-secret --command=openshift-baremetal-install --to {{ workspace_directory.base_path }}/{{ cluster.name }}/openshift-baremetal-install {{ release_image }}"

    - name: Move openshift installer to PATH
      ansible.builtin.copy:
        src: "{{ workspace_directory.base_path }}/{{ cluster.name }}/openshift-baremetal-install/openshift-baremetal-install"
        dest: /usr/bin/openshift-baremetal-install
        remote_src: true
        mode: +x

    - name: Getting ssh public key
      ansible.builtin.slurp:
        src: "~/.ssh/id_rsa_{{ cluster.name }}.pub"
      register: key

    - name: Set SSH Keys as fact
      ansible.builtin.set_fact:
        sshkey: "{{ key['content'] | b64decode }}"

    - name: Firing up install-config.yaml
      ansible.builtin.template:
        src: templates/install-config-sno.j2
        dest: "{{ workspace_directory.base_path }}/{{ cluster.name }}/{{ workspace_directory.config_dir }}/install-config.yaml"
        mode: "0755"

    - name: Generate ignition config
      ansible.builtin.shell: openshift-baremetal-install --dir {{ workspace_directory.base_path }}/{{ cluster.name }}/{{ workspace_directory.config_dir }} create single-node-ignition-config

    - name: Patch live ISO with generate ignition file
      ansible.builtin.shell: coreos-installer iso ignition embed -fi {{ workspace_directory.base_path }}/{{ cluster.name }}/{{ workspace_directory.config_dir }}/bootstrap-in-place-for-live-iso.ign {{ workspace_directory.base_path }}/{{ cluster.name }}/coreos.iso

    - name: Restart net-services
      ansible.builtin.service:
        name: "{{ item }}"
        state: restarted
      loop:
        - NetworkManager
        - dnsmasq

    - name: Virtualization services are enabled
      ansible.builtin.service:
        name: libvirtd
        state: restarted
        enabled: true
      when:
        - ansible_distribution == 'CentOS'

    - name: Virtualization services are enabled
      ansible.builtin.service:
        name: virtqemud
        state: restarted
        enabled: true
      when:
        - ansible_distribution == 'CentOS'
        - ansible_distribution_major_version | int == 9

    - name: Provision OCP node with Terraform
      community.general.terraform:
        project_path: "{{ workspace_directory.base_path }}/{{ cluster.name }}/terraform/sno"
        force_init: true
        variables:
          hostname: "master-sno"
          libvirt_network: "{{ cluster.name }}"
          libvirt_pool: "{{ cluster.name }}"
          vm_net_ip: "{{ cluster_nodes.host_list.sno.ip }}"
          coreos_iso_path: "{{ workspace_directory.base_path }}/{{ cluster.name }}/coreos.iso"
          cpu: "{{ cluster_nodes.specs.sno.vcpu }}"
          memory: "{{ cluster_nodes.specs.sno.mem }}"
          vm_volume_size: "{{ cluster_nodes.specs.sno.disk }}"
          local_volume_enabled: "{{ local_storage.enabled | default(false, true) }}"
          local_volume_size: "{{ local_storage.volume_size | default(omit, true) }}"
          vm_additional_nic: "{{ additional_nic.enabled | default(false, true) }}"
          vm_additional_nic_network: "{{ additional_nic.network | default(cluster.name, true) }}"
        state: present
      register: output_sno

    - name: Start Openshift install
      ansible.builtin.shell: openshift-baremetal-install wait-for install-complete --dir {{ workspace_directory.base_path }}/{{ cluster.name }}/{{ workspace_directory.config_dir }}

    - name: Ensuring httpd-tools is present
      ansible.builtin.yum:
        name: httpd-tools
        state: present

    - name: Ensuring passlib is present
      ansible.builtin.pip:
        name:
          - passlib
          - bcrypt

    - name: Firing yaml configuration template for htpasswd identity provider
      ansible.builtin.template:
        src: templates/htpasswd_provider.j2
        dest: "{{ workspace_directory.base_path }}/{{ cluster.name }}/htpasswd_provider.yaml"
        mode: 0755

    - name: Firing configuration script template for user creation
      ansible.builtin.template:
        src: templates/ocp_user_script.j2
        dest: /tmp/ocp_user.sh
        mode: +x

    - name: Creating htpasswd identity and user
      ansible.builtin.shell: /tmp/ocp_user.sh

    - name: Sleeping 180 seconds...
      ansible.builtin.pause:
        seconds: 180

    - name: Your cluster is ready
      ansible.builtin.debug:
        msg: "Cluster setup finished, grab your kubeconfig in {{ workspace_directory.base_path }}/{{ cluster.name }}/{{ workspace_directory.config_dir }}/auth or log in the console at the address: https://console-openshift-console.apps.{{ cluster.name }}.{{ domain }} with the credentials you chose"
